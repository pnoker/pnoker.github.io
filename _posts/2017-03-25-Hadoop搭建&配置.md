---
layout: post
title: Hadoop 搭建 & 配置
date: 2017-03-25
tag: Hadoop
---

## 一. 安装Java

### Java下载
官网下载合适的jdk,本人使用的是`jdk-7u79-linux-x64.tar.gz`,接下来就以该版本的jdk为例，进行Java环境变量配置

### 创建Java目录
在/usr/local目录下创建java目录，用于存放解压的jdk
```shell
cd /usr/local
mkdir java
```

### 解压jdk
进入java目录
```shell
cd java
tar zxvf jdk-7u79-linux-x64.tar.gz
```

### 配置环境变量
1. 编辑profile文件
```shell
cd /etc
vim profile
```
2. 在文件末尾追加以下配置
```vim
export JAVA_HOME=/usr/local/java/jdk1.7.0_79
export JRE_HOME=/usr/local/java/jdk1.7.0_79/jre
export PATH=$PATH:/usr/local/java/jdk1.7.0_79/bin
export CLASSPATH=./:/usr/local/java/jdk1.7.0_79/lib:/usr/local/jdk7/jdk1.7.0_79/jre/lib
```
3. 刷新profile文件
```shell
source /etc/profile
```


## 二. 安装Hadoop

### 下载Hadoop
[Hadoop Down Page](https://dist.apache.org/repos/dist/release/hadoop/common/)
根据需求选择合适的版本进行下载，本人下载的是`hadoop-2.7.3.tar.gz`,接下来就以该版本的hadoop为例，进行安装&配置

### 创建Hadoop目录
在用户目录下创建`hadoop`目录，用于存放解压的`hadoop`
```shell
cd /home/username
mkdir hadoop

[注]
username为用户名，需要根据实际情况决定
```
### 配置Hadoop Env
1. 编辑`hadoop-env.sh`文件

```shell
cd /home/username/hadoop/hadoop-2.7.3/etc/hadoop/
chmod +x hadoop-env.sh
vim hadoop-env.sh
```
2. 修改其中的`export JAVA_HOME=${JAVA_HOME}`  为 `export JAVA_HOME=/usr/local/java/jdk1.7.0_79`

3. 执行`hadoop-env.sh`

```shell
./hadoop-env.sh
```

### 配置 core-site.xml

```shell
vim core-site.xml
```
指定HDFS的NameNode地址，以及指定Hadoop运行时产生文件的存储目录

```xml
<configuration>

  <property>
    <name>fs.default.name</name>
    <value>hdfs://hadoop-0:9000</value>
  </property>

  <property>
    <name>io.file.buffer.size</name>    
    <value>131072</value>    
  </property>

  <property>
    <name>hadoop.tmp.dir</name>
    <value>file:/usr/local/hadoop/tmp</value>
  </property> 

</configuration>
```

### 配置 hdfs-site.xml

```shell
vim hdfs-site.xml
```

指定HDFS副本的数量

```xml
<configuration>

  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>

  <property>
    <name>dfs.name.dir</name>
    <value>file:/usr/local/hadoop/hdfs/name</value>
  </property>

 <property>
    <name>dfs.data.dir</name>
    <value>file:/usr/local/hadoop/hdfs/data</value>
  </property>

  <property>
    <name>dfs.namenode.secondary.http-address</name>            
    <value>master:9001</value>           
  </property>

  <property>
    <name>dfs.webhdfs.enabled</name>             
    <value>true</value>              
  </property>

</configuration>
```

### 配置 mapred-site.xml

1.重命名

```shell
mv mapred-site.xml.template mapred-site.xml
vim mapred-site.xml
```

2.配置如下

```xml
<configuration>

  <property>
　　<name>mapreduce.framework.name</name>            
    <value>yarn</value>            
  </property>         

  <property>        
    <name>mapreduce.jobhistory.address</name>              
    <value>master:10020</value>              
  </property>        

  <property>        
    <name>mapreduce.jobhistory.webapp.address</name>            
    <value>master:19888</value>            
  </property>     

</configuration>
```

### 配置 yarn-site.xml

```xml
<configuration>

  <property>
    <name>yarn.nodemanager.aux-services</name>           
    <value>mapreduce_shuffle</value>           
  </property>      
        
  <property> 
    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>             
  </property>        
        
  <property>    
    <name>yarn.resourcemanager.address</name>             
    <value>hadoop-0:8032</value>           
  </property>       
       
  <property>     
    <name>yarn.resourcemanager.scheduler.address</name>             
    <value>hadoop-0:8030</value>           
  </property>       
       
  <property>     
    <name>yarn.resourcemanager.resource-tracker.address</name>          
    <value>hadoop-0:8031</value>         
  </property>      
      
  <property>    
    <name>yarn.resourcemanager.admin.address</name>            
    <value>hadoop-0:8033</value>           
  </property>     
       
  <property>     
     <name>yarn.resourcemanager.webapp.address</name>          
     <value>hadoop-0:8088</value>        
  </property>     

</configuration>
```

### 配置masters

```shell
vim masters

#内容填写
hadoop-0
```

### 配置masters

```shell
vim slaves

#内容填写
hadoop-1
hadoop-2
hadoop-3
hadoop-4
hadoop-5
```

**将以上配置完的hadoop复制到每台机器上，然后进行接下来的操作**

### 格式化namenode,只格式一次就行

```shell
hadoop namenode -format
cd /hadoop/hadoop-2.7.3/sbin
./start-all.sh
#根据提示输入密码，如果提示Java_Home，表示没修改hadoop-env.sh中的JAVA_HOME路径，修改完后需要再次执行hadoop-env.sh
```

### 安装验证

1.命令jps

```shell
    jps
```

2.控制台输出一下内容表示安装配置成功

```txt
# Master上打印输出
7548 DataNode
7398 NameNode
6898 ResourceManager
7732 SecondaryNameNode
8336 Jps
7971 NodeManager

#Slave上打印输出
5505 Jps
5121 NodeManager
4992 DataNode
```

### 测试

打开网页[http://localhost:8088/cluster](http://localhost:8088/cluster)可以正常查看,`hostaname`根据实际情况决定，比如我的是`172.16.1.23`


### 主要事项！！

需要将Hadoop进行用户授权
```shell
sudo chown -R group:username hadoop/
sudo chown -R 用户名@用户组 目录名
```
